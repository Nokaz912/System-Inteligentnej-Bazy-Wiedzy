System inteligentnej bazy wiedzy wykorzystującej interfejs w języku naturalnym.

# Zmienne środowiskowe:
- PORT: port na którym uruchomiony jest serwer (domyślnie 3000)
- OLLAMA_HOST: nazwa hosta Ollamy (domyślnie localhost)
- OLLAMA_PORT: port na którym uruchomiona jest Ollama (domyślnie 11434)
- OLLAMA_MODEL: model LLM w Ollamie (domyślnie llama2)

# Dokumentacja OpenAPI:
- uruchamiasz serwer poleceniem "npm run dev"
- wchodzisz na adres localhost:3000/api/v1/documentation

# Aplikacja webowa:
- uruchamiasz aplikację poleceniem "npm start"
- aplikacja uruchamia się pod adresem localhost:80